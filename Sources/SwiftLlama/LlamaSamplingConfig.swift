//
//  LlamaSamplingConfig.swift
//  LlamaSwift
//
//  Created by Piotr Gorzelany on 07/02/2025.
//

/// A configuration that defines the parameters for the token sampling process.
///
/// This configuration is used to initialize a `LlamaSampler`, which controls how new tokens are generated by the model.
/// It includes options for controlling randomness, applying nucleus and top-k sampling, and enforcing constraints
/// like grammars and repetition penalties.
public struct LlamaSamplingConfig: Equatable, Sendable {
    /// Controls the randomness of the generated text.
    ///
    /// Higher values (e.g., 0.8) make the output more random and creative, while lower values (e.g., 0.2)
    /// make it more deterministic and focused. A value of 0.0 makes the sampling greedy, always picking the
    /// most likely token.
    public let temperature: CFloat

    /// The seed for the random number generator.
    ///
    /// Using the same seed with the same prompt and parameters will produce the same output,
    /// ensuring reproducibility.
    public let seed: UInt32

    /// The cumulative probability cutoff for nucleus sampling (Top-P).
    ///
    /// The model considers only the tokens whose cumulative probability exceeds this value.
    /// For example, a value of 0.95 means that the top 95% of tokens by probability mass are considered
    /// for sampling. This helps in cutting off the long tail of low-probability tokens.
    public let topP: Float

    /// The number of most likely tokens to consider for sampling (Top-K).
    ///
    /// If set, the model will only sample from the `topK` most likely tokens from the vocabulary.
    /// A value of `nil` disables Top-K sampling.
    public let topK: Int32?

    /// The minimum number of tokens to keep after applying Top-P or Top-K sampling.
    ///
    /// This ensures that there are always at least `minKeep` candidates to sample from.
    public let minKeep: Int

    /// An optional grammar to constrain the model's output to a specific format.
    /// If `nil`, no grammar is used.
    public let grammarConfig: LlamaGrammarConfig?

    /// Configuration for repetition penalties.
    /// Set to `nil` to disable all repetition penalties.
    /// Defaults to a standard configuration.
    public let repetitionPenaltyConfig: LlamaRepetitionPenaltyConfig?

    /// Initializes a new sampling configuration with the specified parameters.
    ///
    /// - Parameters:
    ///   - temperature: Controls the randomness of the output. Defaults to a balanced value.
    ///   - seed: The seed for the random number generator.
    ///   - topP: The cumulative probability cutoff for nucleus sampling. Defaults to 0.95.
    ///   - topK: The number of most likely tokens to consider. Defaults to `nil` (disabled).
    ///   - minKeep: The minimum number of tokens to keep after sampling. Defaults to 1.
    ///   - grammarConfig: An optional grammar to enforce a specific output format. Defaults to `nil`.
    ///   - repetitionPenaltyConfig: An optional configuration for repetition penalties. Defaults to a standard configuration.
    public init(
        temperature: CFloat,
        seed: UInt32,
        topP: Float = 0.95,
        topK: Int32? = nil,
        minKeep: Int = 1,
        grammarConfig: LlamaGrammarConfig? = nil,
        repetitionPenaltyConfig: LlamaRepetitionPenaltyConfig? = LlamaRepetitionPenaltyConfig()
    ) {
        self.temperature = temperature
        self.seed = seed
        self.topK = topK
        self.topP = topP
        self.minKeep = minKeep
        self.grammarConfig = grammarConfig
        self.repetitionPenaltyConfig = repetitionPenaltyConfig
    }
}
